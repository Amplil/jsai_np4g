@Article{saito:11,
  author = "斉藤 成海",
  title = "数学的な見方や考え方を基盤とした論理的な思考",
  journal = "群馬大学教育実践研究",
  year = 2011,
  volume = 28,
  pages = "31--37"
}
@book{伊藤,
   author = "伊藤斉志",
   yomi = "Seiji Ito",
   title = "遺伝的アルゴリズムの基礎",
   publisher = "オーム社",
   year = 1995,
}
@Article{dartmouth,
  author = "John McCarthy and Marvin L. Minsky and Nathaniel Rochester and Claude E. Shannon",
  title = "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955",
  journal = "AI Magazine",
  year = 2006,
  volume = 27,
  number = 4,
}
@article{LogicTheorist,
    author = {Leo Gugerty},
    title ={Newell and Simon's Logic Theorist: Historical Background and Impact on Cognitive Modeling},
    journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
    volume = {50},
    number = {9},
    pages = {880-884},
    year = {2006},
    doi = {10.1177/154193120605000904},
    URL = {https://doi.org/10.1177/154193120605000904},
    eprint = {https://doi.org/10.1177/154193120605000904},
    abstract = { Fifty years ago, Newell and Simon (1956) invented a “thinking machine” called the Logic Theorist. The Logic Theorist was a computer program that could prove theorems in symbolic logic from Whitehead and Russell's Principia Mathematica. This was perhaps the first working program that simulated some aspects of peoples' ability to solve complex problems. The Logic Theorist and other cognitive simulations developed by Newell and Simon in the late 1950s had a large impact on the newly developing field of information-processing (or cognitive) psychology. Many of the novel ideas about mental representation and problem solving instantiated in the Logic Theorist are still a central part of the theory of cognitive psychology, and are still used in modeling the complex tasks studied in human factors psychology. This paper presents some of the theoretical precursors of the Logic Theorist, describes the principles and implementation of the program, and discusses its immediate and long-term impacts. }
}
@article{tsukimoto:00,
    author="月本 洋",
    title="パターン推論-ニューラルネットワークの論理的推論-",
    journal="電子情報通信学会論文誌. D-2, 情報・システム 2-パターン処理",
    ISSN="09151923",
    publisher="一般社団法人電子情報通信学会",
    year="2000",
    month="feb",
    volume="00083",
    number="00002",
    pages="744-753",
    URL="https://ci.nii.ac.jp/naid/110003183723/",
    DOI="",
}
@article{sudo:07,
  title={知識を追加的に獲得可能なパターンベースの推論システム},
  author={須藤 明人 and 佐藤 彰洋 and 長谷川 修},
  journal={人工知能学会全国大会論文集},
  volume={JSAI07},
  number={ },
  pages={3E94-3E94},
  year={2007},
  doi={10.11517/pjsai.JSAI07.0_3E94}
}
@article{gnp,
    title = "Genetic network programming - application to intelligent agents",
    abstract = "Recently many studies have been made on automatic design of the complex systems by using the evolutionary optimization techniques such as Genetic Algorithms (GA), Evolution Strategy (ES), Evolutionary Programming (EP) and Genetic Programming (GP). It is generally recognized that these techniques are very useful for optimizing fairly complex systems such as generation of intelligent behavior sequences of robots. In this paper, a new method named Genetic network Programming (GNP) is proposed in order to acquire these behavior sequences efficiently. GNP is composed of plural nodes for agents to execute simple judgment/processing and they are connected with each other to form a network structure. Agents behave according to the contents of the nodes and their connections in GNP. In order to obtain better structure, GNP changes itself by using evolutionary optimization techniques.",
    author = "H. Katagiri and K. Hirasawa and J. Hu",
    year = "2000",
    month = dec,
    day = "1",
    language = "English",
    volume = "5",
    pages = "3829--3834",
    journal = "Proceedings of the IEEE International Conference on Systems, Man and Cybernetics",
    issn = "0884-3627",
    publisher = "Institute of Electrical and Electronics Engineers Inc.",
    note = "2000 IEEE International Conference on Systems, Man and Cybernetics ; Conference date: 08-10-2000 Through 11-10-2000",
}
@book{adfs,
   author = "Koza, John R.",
   title = "Genetic programming II : automatic discovery of reusable programs",
   publisher = "MIT Press",
   year = 1992,
}
@Misc{copilot,
  title        = "{GitHub Copilot}",
  howpublished = "\url{https://copilot.github.com/}"
}
@article{gpt3,
  author    = {Tom B. Brown and
               Benjamin Mann and
               Nick Ryder and
               Melanie Subbiah and
               Jared Kaplan and
               Prafulla Dhariwal and
               Arvind Neelakantan and
               Pranav Shyam and
               Girish Sastry and
               Amanda Askell and
               Sandhini Agarwal and
               Ariel Herbert{-}Voss and
               Gretchen Krueger and
               Tom Henighan and
               Rewon Child and
               Aditya Ramesh and
               Daniel M. Ziegler and
               Jeffrey Wu and
               Clemens Winter and
               Christopher Hesse and
               Mark Chen and
               Eric Sigler and
               Mateusz Litwin and
               Scott Gray and
               Benjamin Chess and
               Jack Clark and
               Christopher Berner and
               Sam McCandlish and
               Alec Radford and
               Ilya Sutskever and
               Dario Amodei},
  title     = {Language Models are Few-Shot Learners},
  journal   = {CoRR},
  volume    = {abs/2005.14165},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.14165},
  eprinttype = {arXiv},
  eprint    = {2005.14165},
  timestamp = {Wed, 03 Jun 2020 11:36:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{KnowledgeAI,
  title={Knowledge acquisition: issues, techniques, and methodology},
  author={Yihwa Irene Liou},
  booktitle={SIGBDP '90},
  year={1990}
}
@article{TENENBAUM2006,
title = {Theory-based Bayesian models of inductive learning and reasoning},
journal = {Trends in Cognitive Sciences},
volume = {10},
number = {7},
pages = {309-318},
year = {2006},
note = {Special issue: Probabilistic models of cognition},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2006.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661306001343},
author = {Joshua B. Tenenbaum and Thomas L. Griffiths and Charles Kemp},
abstract = {Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. We argue that both components are necessary to explain the nature, use and acquisition of human knowledge, and we introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations.}
}
@inproceedings{hodohara2012reinforcement,
  title={Reinforcement learning with phased approach for fast learning},
  author={Hodohara, Norifumi and Murakami, Yuichi and Nakamura, Shingo and Hashimoto, Shuji},
  booktitle={Proceedings of the International Symposium on Artificial Life and Robotics (AROB 17th'12)},
  pages={930--933},
  year={2012}
}
