%% 和文論文用のテンプレート
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 1. 和文原稿
% \documentclass[originalpaper]{jsaiart}     % 原著論文 Original Paper
%\documentclass[blindreview]{jsaiart}      % 査読用
%
% \documentclass[shortpaper]{jsaiart}       % 速報論文 Short Paper
\documentclass[exploratorypaper]{jsaiart} % 萌芽論文 Exploratory Research Paper
% \documentclass[Specialissue]{jsaiart}     % 特集 Special Issue
% \documentclass[specialissue]{jsaiart}     % 小特集 Special Issue
% \documentclass[interimreport]{jsaiart}    % 報告 An Interim Report
% \documentclass[surveypaper]{jsaiart}      % 解説 Survey Paper
% \documentclass[aimap]{jsaiart}            % AIマップ AI map
% \documentclass[specialpaper]{jsaiart}     % 特集論文 Special Paper
% \documentclass[invitedpaper]{jsaiart}     % 招待論文 Invited Paper
%

%\usepackage{graphics}
\usepackage[dvipdfmx]{graphicx}
\usepackage{url}
%\usepackage[dvipdfmx]{profile-2e}

%% ページ番号の指定，掲載時に学会の方で決定します．
% \setcounter{page}{1}
% \setcounter{volpage}{1}


%%% amsmathパッケージの注意点 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \usepackpage{amsmath}
% 数式番号の参照は \ref ではなく，\eqref を用いること
% documentclass のオプションに fleqnを指定すること
% 例: \documentclass[technicalpaper,fleqn]{jsaiart}

\Vol{12}
\No{1}
\jtitle{一般化のためのネットワークプログラミング}
% \jtitle[柱用和文タイトル]{和文タイトル}
\jsubtitle{論理的推論によるビットNOT演算プログラムの獲得}
\etitle{NP4G : Network Programming for Generalization}
\esubtitle{Getting a bitwise NOT operator's program by logical inference}

% \manyauthor % 著者が3名以下の場合はこの行を消すこと

%%% 著者名の注意点 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 所属先が同じ著者が連続する場合，その中の先頭の著者のみ \affiliation
% を用い，残りの所属先には \sameaffiliation を使う
% ただし，所属先が同じでも連続していない場合は \affliation を使う
% 名前が長い場合は \name の代りに \longname を使う

\author{%
 \name{原}{匠一郎}{Shoichiro Hara}
 \affiliation{名古屋市立大学}%
     {Nagoya City University}%
     {s.hara@nsc.nagoya-cu.ac.jp}
\and
 \name{渡邊}{裕司}{Yuji Watanabe}
 \sameaffiliation{yuji@nsc.nagoya-cu.ac.jp}
}

\begin{keyword}
logical inference, understanding causality, NP4G, GA, GP, GNP
\end{keyword}

\begin{summary}
 In this study, We propose NP4G : Network Programming for Generalization. NP4G is available on GitHub\footnotemark[1].
\end{summary}

\begin{document}
\maketitle
\footnotetext[1]{公開予定}
\section{はじめに}
人工知能における論理的推論に関する研究は歴史が長く，エキスパートシステムをはじめとして，さまざまなアプローチによる研究が行われてきた．しかし依然として，あらゆる知識に対し自ら学習をし，その内容を活かして別の問題に対して論理的に推論し答えを導くような，汎用的で柔軟な人工知能の実現には至っていない．
近年のニューラルネットワークを活用した人工知能の発達はめざましいが，論理的推論という点において，課題が残る．機械学習の発展における次の段階として，概念関係の理解は非常に重要である．

人工知能という言葉が初めてできたダートマス会議では，機械が言語を使うことができるようにする方法の探究，機械上での抽象化と概念の形成，今は人間にしか解けない問題を機械で解くこと，機械が自分自身を改善する方法などの探究の試みがなされるだろう\cite{dartmouth}．



本研究では，論理的推論を行うことができる一般化のためのネットワークプログラミング(NP4G: Network Programming for Generalization)を提案する．

ソースコードはGitHubリポジトリで見ることができる\footnotemark[1]．

\section{関連研究}
本研究では，一般化のためのネットワークプログラミングを提案する．この目的と関連した研究として，(1)GP / GNP，(2)論理的推論に関する研究，(3)自動プログラミングに関する研究を紹介する．
\subsection{遺伝的プログラミング}
類似研究として，GNPが挙げられる．
GPは木構造のみを扱うが，これをネットワークに拡張したものが遺伝的ネットワークプログラミング(GNP:Genetic Network Programming)である\cite{gnp}．

GP/GNPでは各ノードを単純な処理をする最小単位と考え，それらを木構造状またはネットワーク状に接続することによりプログラムを構築する．

ネットワークにすることで，それぞれのノードの組み合わせで，プログラムを自動的に構築することができる．

判定ノード，処理ノード，スタートノードに分類することができる．

\subsection{論理的推論}
広義に論理的推論は，演繹的推論と帰納的推論，類比的推論の３つで構成されている（『算数・数学科重要用語300の基礎知識』p.106）．
論理的思考の代表的なものとして「帰納的な考え方」，「類推的な考え方」，「一般化の考え方」，「記号化の考え方」などがある\cite{saito:11}．

ニューラルネットワークの手法では，確かに個々のデータの特徴の共通点を拾い出すことができるため，その点においては一般化ができると言えるが，その手続きはブラックボックス化されており，論理的な推論における一般化とは言えない．ニューラルネットワークでは学習に基づき推論を行うが，その推論の思考プロセスは見えにくく，論理的でない．
ある程度の分析はできるものの[出典]，明確な重みづけの基準を理解することは非常に困難である．

ニューラルネットワークでは原因と効果や，なぜ関連性や相関があるのかを解釈できない．特に，創造や計画，推論を伴うタスクは得意としない．これと同様に，AIが学習を一般化することに限界がある．一般化の欠如は大きい問題である．
また，学習には大量のデータが必要であり，このことからも論理的推論でないことがわかる．

ニューラルネットワークでは基本ネットワークの構成は変えられず，重みを変化させることで学習するが，NP4Gではネットワークの構成を変えることで，学習する．

ニューラルネットワークによって論理的推論であるパターン推論を行った研究が報告されている\cite{tsukimoto:00}\cite{sudo:07}．


\subsection{自動プログラミング}
Logic Theorist\cite{LogicTheorist}は探索木とヒューリスティクスを利用し，人間の論理的推論を模倣することを意図して作られた．

最近では，GPT3\cite{gpt3}などの手法を用いた自動プログラミング

プログラミングの補完機能
一般に公開されている膨大なコードから学習をし，開発者の書こうとしているコードを予測して，その続きを提案するような機能も出てきている\cite{copilot}．

これらは言語生成アルゴリズムであり，論理的推論によりコードを生成しているわけではない．

\section{提案手法}
NP4G (Network Programming for Generalization) とは，教師データに基づき，ネットワークで表現されるプログラムを自動生成することで，論理的推論における一般化を行う手法である．

教師データ（入力と出力のペア）に合致するネットワークを探索する．

簡単な機能を持った複数のノード素子をネットワーク状に接続し，プログラムを記述することのできるモデル

入力をある規則に従って変換し出力することのできるモデル

ノード間の接続を教師データに合わせて変更することによって，教師データに合致するような処理のできるプログラムを得る．

ネットワークを生成する．

NP4G (Network Programming for Generalization)は論理的推論における一般化のモデル生成を目的とする．

NP4GはGNPから遺伝的操作であることの意味をなくし（制限をなくし），一般化のための手法であるという意味を付け加えたものであるといえる．

人工知能を使った論理的推論における一般化に関しては今のところ関連研究が見当たらない．→論理的推論であるパターン推論の論文はある．
\subsection{繰り返し処理}


\subsection{自動定義関数(ADFs)}
GPでは，プログラムの進化の際に高速化が望めるなどの理由から自動関数定義(ADFs:Automatically Defined Functions)\cite{adfs}が用いられる．ADFsはGPの性能を向上させる目的で，問題に存在するモジュール性を利用する方法である．
\subsection{段階的学習}
段階的にネットワークを得て，ADFsとしてネットワークを再利用することで，はじめから複雑なネットワークを得るときよりも速く学習をすることができる．
ヒトの学習でも，最初は簡単なレベルの学習から始め，徐々に難易度を上げていくと，無理なく学習できる．

\subsection{提案手法を使う利点}
いわゆる一般化をすることができる．論理的推論によってプログラムを自動生成するため，論理的でない推論である手法と比べて，一般化をするために必要な教師データの数は数個程度と非常に少なく済む．ニューラルネットワークとは違い，構築されたプログラム自体がネットワークの形になっているため，どのような処理をしているのか明らかである．

\section{ビットNOT演算プログラムの獲得}
NP4Gを使って，ビットNOT演算プログラムを自動で構築する場合を考える．

\subsection{設定}
NP4Gを用いて，ビットNOT演算プログラムを獲得する実験を行った．

\subsection{与えられる関数}
\subsubsection{div関数}
スペースを区切りとして，文字列を分けリスト表記にする．

\begin{figure}[t]
    \begin{center}
        %\includegraphics[width=90mm]{ab0ex-mtphu.eps}
        \includegraphics[width=50mm]{div.png}
        %\epsfile{file=ab0ex-mtphu.eps,width=90mm}
    \end{center}
    \capwidth=50mm %
    \caption{図の説明文... }
\end{figure}



\subsubsection{sum関数}
リストの要素を，スペースを挟んで結合し，1つの文字列にする．

\subsubsection{equal関数}
2つの入力ノードの値が一致するとき[TRUE]を出力する．それ以外は[FALSE]を出力する．
\subsubsection{制御ゲート関数}
入力のどちらかが[TRUE]である場合はもう片方のリンクの値を通し，それ以外は[NULL]を出力する．
\subsubsection{制御NOTゲート関数}
入力のどちらかが[FALSE]である場合はもう片方のリンクの値を通し，それ以外は[NULL]を出力する．

\subsection{段階的学習の手順}
1. 0の入力に対して1の出力を得るネットワークをadfsリストに登録する．
2. 1の入力に対して0の出力を得るネットワークをadfsリストに登録する．
3. 0の入力に対して1の出力，1の入力に対して0の出力を得るネットワークをadfsリストに登録する．

\section{実験}
ビットNOT演算プログラムを自動で構築するプログラムを10回実行する．
\subsection{結果}
実験の結果を\ref{tbl:result}に示す．

\begin{table}[htbp]
\centering
\caption{実験結果}
\label{tbl:result}
\begin{tabular}{cc}
    \hline
     実行時間(min) & ノードの数\\
    \hline
    120 & 〈命題1〉 \\
    100 & 3 \\
    \hline
    130 & ［仮定1］ \\
    200 & 3 \\
    \hline
    120 & 〈命題1〉 \\
    100 & 3 \\
    \hline
    130 & ［仮定1］ \\
    200 & 3 \\
    \hline
    120 & 〈命題1〉 \\
    100 & 3 \\
    \hline
    130 & ［仮定1］ \\
    200 & 3 \\
    \hline
\end{tabular}
\end{table}

\subsubsection{得られたネットワーク}
\ref{fig:net}に示すようにネットワークが得られた．
\subsubsection{評価}
平均を示す．
\subsubsection{考察}

\begin{figure*}[t]
    \begin{center}
        %\includegraphics[width=90mm]{ab0ex-mtphu.eps}
        \includegraphics[width=120mm]{network.jpg}
        %\epsfile{file=ab0ex-mtphu.eps,width=90mm}
    \end{center}
    \capwidth=90mm %
    \caption{図の説明文... }
    \label{fig:net}
\end{figure*}

\section{おわりに}
一般化のためのネットワークプログラミング(NP4G)を提案した．NP4Gを使うことで，論理的推論によるビットNOT演算プログラムを獲得できることを示した．

\subsection{今後の課題}
ビットNOT演算子だけでなく，他のプログラムもNP4Gを使って自動で構築できるか試してみる必要がある．
チューリング完全であることを証明することができれば，広く自動プログラミングとして応用可能であることが理論的に示すことができる．

\bibliography{btx_np4g}
\bibliographystyle{jsai}

%\appendix
%\section{付録のタイトル1}
%付録の本文1
%\section{付録のタイトル2}
%付録の本文2

% 著者の姓と名の間は半角スペースで区切る
% 略歴は200字以内
\begin{biography}
\profile{s}{原 匠一郎}{2018年3月名城大学理工学部電気電子工学科卒業．2020年3月名古屋市立大学大学院システム自然科学研究科博士前期課程 修了．現在，名古屋市立大学大学院理学研究科博士後期課程在籍中．情報処理学会会員．}
\profile{n}{渡邊 裕司}{著者2の略歴}
%\profile*{m}{著者姓 名}{前掲\kern-.5zw （Vol.X，No.Y，p.Z）\kern-.5zw 参照．}
\end{biography}

\end{document}
